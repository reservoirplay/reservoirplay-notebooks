{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ESN波形分類3（音声分類への応用）"
      ],
      "metadata": {
        "id": "w9LpQkk1BBhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 初期設定"
      ],
      "metadata": {
        "id": "zA4bAGXt2jdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown 各種パラメータを変更可能です（デフォルトのまま実行してもOK）\n",
        "\n",
        "# 音の特徴を何次元の数値で表現するか\n",
        "N_MFCC = 13  # @param {type:\"number\"}\n",
        "\n",
        "# 分析フレームを移動させる歩幅（小さいほど時間分解能が高い）default: 20ms (8000Hz の場合)\n",
        "HOP_LEN = 160 # @param {type:\"number\"}\n",
        "\n",
        "# 一度の分析に使う音声データの長さ（長いほど周波数分解能が高い）default: 50ms (8000Hz の場合)\n",
        "WIN_LEN = 400 # @param {type:\"number\"}\n",
        "\n",
        "# リザバーのニューロン数\n",
        "N_RESERVOIR     = 400 # @param {type:\"number\"}\n",
        "\n",
        "# スペクトル半径\n",
        "SPECTRAL_RADIUS = 0.9 # @param {type:\"number\"}\n",
        "\n",
        "# 内部結合の密度\n",
        "DENSITY         = 0.05 # @param {type:\"number\"}\n",
        "\n",
        "# リーク率\n",
        "LEAK_RATE       = 0.3 # @param {type:\"number\"}\n",
        "\n",
        "# 入力スケーリング\n",
        "INPUT_SCALING   = 0.8 # @param {type:\"number\"}\n",
        "\n",
        "# リッジ回帰の正則化係数\n",
        "RIDGE_REG       = 1e-5 # @param {type:\"number\"}\n",
        "\n",
        "\n",
        "print(f\"MFCCの次元数: {N_MFCC }\")\n",
        "print(f\"MFCCフレーム歩幅: {HOP_LEN}\")\n",
        "print(f\"MFCCフレーム長: {WIN_LEN}\")\n",
        "print(f\"リザバーのニューロン数: {N_RESERVOIR}\")\n",
        "print(f\"スペクトル半径: {SPECTRAL_RADIUS}\")\n",
        "print(f\"結合密度: {DENSITY}\")\n",
        "print(f\"リーク率: {LEAK_RATE}\")\n",
        "print(f\"入力スケーリング: {INPUT_SCALING}\")\n",
        "print(f\"リッジ回帰の正則化係数: {RIDGE_REG}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-k4QZmMt2mLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown チェックされているクラスを学習対象とします（デフォルトのまま実行してもOK）\n",
        "\n",
        "# チェックボックスの定義\n",
        "yes = True #@param {type:\"boolean\"}\n",
        "no = True #@param {type:\"boolean\"}\n",
        "stop = True #@param {type:\"boolean\"}\n",
        "cat = False #@param {type:\"boolean\"}\n",
        "dog = False #@param {type:\"boolean\"}\n",
        "one = False #@param {type:\"boolean\"}\n",
        "two = False #@param {type:\"boolean\"}\n",
        "three = False #@param {type:\"boolean\"}\n",
        "\n",
        "# 各クラスからランダムに取得する数\n",
        "N_PER_CLASS = 200 # @param {type:\"number\"}\n",
        "\n",
        "# 選択されたクラスをリスト化する処理\n",
        "# クラス名をリストに定義\n",
        "all_classes = ['yes', 'no', 'stop', 'cat', 'dog', 'one', 'two', 'three']\n",
        "\n",
        "# locals()（現在の変数一覧）から、チェックが入っているものだけを抜き出す\n",
        "selected_classes = [name for name in all_classes if locals().get(name)]\n",
        "\n",
        "\n",
        "print(f\"対象クラス: {selected_classes}\")\n",
        "print(f\"1クラス当たりの取得データ数: {N_PER_CLASS}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sStJ5dfgFkRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセットのダウンロード（初回実行のみ１～２分かかる）"
      ],
      "metadata": {
        "id": "W8k5yD2qXxqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown  データセットをダウンロードします。１～２分程度かかります。<br>\n",
        "# @markdown  すでにダウンロードされている場合はスキップされますので「すべてのセルを実行」をクリックしても問題ありません。\n",
        "\n",
        "# Google Speech Commands Dataset\n",
        "\n",
        "%%bash\n",
        "# 既にダウンロード済みならスキップ、未DLならDLして展開\n",
        "if [ ! -f speech_commands_v0.02.tar.gz ]; then\n",
        "  wget http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
        "  tar -xf speech_commands_v0.02.tar.gz\n",
        "else\n",
        "  echo \"already downloaded, skip download and extract\"\n",
        "fi"
      ],
      "metadata": {
        "id": "YCjejMIbx8dm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 指定したクラスからランダムにデータを選択"
      ],
      "metadata": {
        "id": "0UqwczmcSdKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown  指定したクラスからランダムにデータを選びます\n",
        "\n",
        "import random\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "SR = 8000\n",
        "DURATION = 1.0\n",
        "SAMPLES = int(SR * DURATION)\n",
        "\n",
        "CLASSES = selected_classes\n",
        "\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "for label, cname in enumerate(CLASSES):\n",
        "    # クラスフォルダ内の wav をすべて対象にする（話者制限なし）\n",
        "    files = [\n",
        "        f for f in os.listdir(cname)\n",
        "        if f.endswith(\".wav\")\n",
        "    ]\n",
        "\n",
        "    if len(files) == 0:\n",
        "        print(f\"[WARN] クラス {cname} に wav がありません。スキップします。\")\n",
        "        continue\n",
        "\n",
        "    # ランダムにシャッフル\n",
        "    np.random.shuffle(files)\n",
        "\n",
        "    # N_PER_CLASS に制限\n",
        "    files = files[:N_PER_CLASS]\n",
        "\n",
        "    print(f\"クラス {cname}: {len(files)} 個（ランダム抽出）\")\n",
        "\n",
        "    for f in files:\n",
        "        path = os.path.join(cname, f)\n",
        "        wav, _ = librosa.load(path, sr=SR)\n",
        "\n",
        "        if len(wav) > SAMPLES:\n",
        "            wav = wav[:SAMPLES]\n",
        "        elif len(wav) < SAMPLES:\n",
        "            wav = np.pad(wav, (0, SAMPLES - len(wav)))\n",
        "\n",
        "        X_list.append(wav.astype(np.float32))\n",
        "        y_list.append(label)\n",
        "\n",
        "X = np.stack(X_list)\n",
        "y = np.array(y_list)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"クラスごとの件数:\", np.bincount(y, minlength=len(CLASSES)))"
      ],
      "metadata": {
        "id": "4elBYGraqJ6U",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 選択したデータの確認"
      ],
      "metadata": {
        "id": "Yv42fPdEgRS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown  選択したデータからランダムに１つ選択し音を確認できます（実行のたびに変わります）\n",
        "\n",
        "# 学習データの中からランダムに波形を選び、グラフ描画と音声出力\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "\n",
        "def show_random_sample(volume=0.5):\n",
        "    \"\"\"\n",
        "    学習データ X, y からランダムに1つ取り出し、\n",
        "    波形を描画して、音声を再生する。\n",
        "    volume: 0.0〜1.0 で音量スケール\n",
        "    \"\"\"\n",
        "    idx = np.random.randint(0, len(X))\n",
        "    wav = X[idx]\n",
        "    label_id = int(y[idx])\n",
        "    label_name = CLASSES[label_id]\n",
        "\n",
        "    print(f\"index = {idx}, label = {label_name} (id={label_id})\")\n",
        "\n",
        "    # 時間軸（秒）\n",
        "    t = np.arange(len(wav)) / SR\n",
        "\n",
        "    # 波形プロット（全体）\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.plot(t, wav)\n",
        "    plt.title(f\"Waveform: {label_name}\")\n",
        "    plt.xlabel(\"Time [s]\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # 音量調整して再生\n",
        "    return Audio(wav * volume, rate=SR, normalize=False)\n",
        "\n",
        "# 実行するたびにランダムなサンプルが出る\n",
        "audio_obj = show_random_sample(volume=0.5)\n",
        "audio_obj"
      ],
      "metadata": {
        "id": "7sgVB2_Rf6Gh",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 無音区間削除"
      ],
      "metadata": {
        "id": "2vOh3xLzFgoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown  選択した全てのデータについて無音区間を削除します\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def trim_silence_rms(\n",
        "    wav,\n",
        "    sr,\n",
        "    frame_length=400,   # 50ms @ 8kHz\n",
        "    hop_length=160,     # 20ms\n",
        "    rms_thresh=0.02     # 無音判定の閾値（重要）\n",
        "):\n",
        "    \"\"\"\n",
        "    RMSベースで無音区間を除去した波形を返す\n",
        "    \"\"\"\n",
        "    # RMS計算（shape: (1, n_frames)）\n",
        "    rms = librosa.feature.rms(\n",
        "        y=wav,\n",
        "        frame_length=frame_length,\n",
        "        hop_length=hop_length\n",
        "    )[0]\n",
        "\n",
        "    # 有音フレームのインデックス\n",
        "    keep = rms > rms_thresh\n",
        "\n",
        "    if not np.any(keep):\n",
        "        # 全部無音と判定された場合は元の波形を返す\n",
        "        return wav\n",
        "\n",
        "    # フレーム → サンプル範囲に変換\n",
        "    idx = np.where(keep)[0]\n",
        "    start = idx[0] * hop_length\n",
        "    end   = min(len(wav), idx[-1] * hop_length + frame_length)\n",
        "\n",
        "    return wav[start:end]\n",
        "\n",
        "\n",
        "X_trim = []\n",
        "\n",
        "for wav in X:\n",
        "    wav_trim = trim_silence_rms(\n",
        "        wav,\n",
        "        sr=SR,\n",
        "        frame_length=WIN_LEN,   # MFCCと合わせる\n",
        "        hop_length=HOP_LEN,\n",
        "        rms_thresh=0.02\n",
        "    )\n",
        "    X_trim.append(wav_trim.astype(np.float32))\n",
        "\n",
        "# list → object array（長さが変わるため）\n",
        "X_trim = np.array(X_trim, dtype=object)"
      ],
      "metadata": {
        "id": "9aNvoDqaFj8X",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown  選択したデータからランダムに１つ選択し、元波形と無音カット後の波形を確認できます（実行のたびに変わります）\n",
        "\n",
        "# 波形確認２つ並べる\n",
        "\n",
        "# 学習データの中からランダムに波形を選び、\n",
        "# 元波形 X と 無音カット後 X_trim を上下に描画＆再生\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def show_random_sample_with_trim(volume=0.5):\n",
        "    \"\"\"\n",
        "    学習データ X, X_trim, y からランダムに1つ取り出し、\n",
        "    元波形と無音カット後波形を上下に表示して音声を再生する。\n",
        "    \"\"\"\n",
        "    idx = np.random.randint(0, len(X))\n",
        "\n",
        "    wav_org  = X[idx]\n",
        "    wav_trim = X_trim[idx]\n",
        "\n",
        "    label_id = int(y[idx])\n",
        "    label_name = CLASSES[label_id]\n",
        "\n",
        "    print(f\"index = {idx}, label = {label_name} (id={label_id})\")\n",
        "    print(f\"original length = {len(wav_org)}, trimmed length = {len(wav_trim)}\")\n",
        "\n",
        "    # 時間軸\n",
        "    t_org  = np.arange(len(wav_org))  / SR\n",
        "    t_trim = np.arange(len(wav_trim)) / SR\n",
        "\n",
        "    # ==== 波形プロット ====\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(10, 5), sharex=False)\n",
        "\n",
        "    axes[0].plot(t_org, wav_org)\n",
        "    axes[0].set_title(\"Original waveform (X)\")\n",
        "    axes[0].set_ylabel(\"Amplitude\")\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    axes[1].plot(t_trim, wav_trim)\n",
        "    axes[1].set_title(\"Trimmed waveform (X_trim)\")\n",
        "    axes[1].set_xlabel(\"Time [s]\")\n",
        "    axes[1].set_ylabel(\"Amplitude\")\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ==== 音声再生 ====\n",
        "    print(\"▶ Original\")\n",
        "    display(Audio(wav_org * volume, rate=SR, normalize=False))\n",
        "    print(\"▶ Trimmed\")\n",
        "    display(Audio(wav_trim * volume, rate=SR, normalize=False))\n",
        "\n",
        "# 実行するたびにランダムなサンプルが出る\n",
        "audio_obj = show_random_sample_with_trim(volume=0.5)\n",
        "audio_obj"
      ],
      "metadata": {
        "id": "qy61cSHGNOyy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 正規化"
      ],
      "metadata": {
        "id": "1AmkH0Q4RjZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown  選択した全てのデータについて正規化します\n",
        "\n",
        "# =========================\n",
        "# 正規化（無音カット後の波形 X_trim → X_norm）\n",
        "# =========================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X_norm = []\n",
        "\n",
        "for wav in X_trim:\n",
        "    max_abs = np.max(np.abs(wav)) + 1e-8\n",
        "    X_norm.append(wav / max_abs)\n",
        "\n",
        "# object配列にして長さ違いを許容\n",
        "X_norm = np.array(X_norm, dtype=object)\n",
        "\n",
        "print(\"正規化完了\")"
      ],
      "metadata": {
        "id": "NSSn-cGjRmhw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown  選択したデータからランダムに１つ選択し、元波形と正規化後の波形を確認できます（実行のたびに変わります）\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 正規化前後の波形を「全体」で比較表示\n",
        "# （何度も実行する想定）\n",
        "# =========================\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def show_random_norm_compare(volume=0.3):\n",
        "    idx = np.random.randint(0, len(X_norm))\n",
        "\n",
        "    wav_before = X_trim[idx]\n",
        "    wav_after  = X_norm[idx]\n",
        "\n",
        "    label_id = int(y[idx])\n",
        "    label_name = CLASSES[label_id]\n",
        "\n",
        "    print(f\"index = {idx}, label = {label_name} (id={label_id})\")\n",
        "    print(f\"length: before={len(wav_before)}, after={len(wav_after)}\")\n",
        "\n",
        "    t_before = np.arange(len(wav_before)) / SR\n",
        "    t_after  = np.arange(len(wav_after)) / SR\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # --- 正規化前 ---\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(t_before, wav_before)\n",
        "    plt.title(\"Before normalization (X_trim)\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    # --- 正規化後 ---\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(t_after, wav_after)\n",
        "    plt.title(\"After normalization (X_norm)\")\n",
        "    plt.xlabel(\"Time [s]\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ==== 音声再生 ====\n",
        "    print(\"▶ Before\")\n",
        "    display(Audio(wav_before * volume, rate=SR, normalize=False))\n",
        "    print(\"▶ After\")\n",
        "    display(Audio(wav_after  * volume, rate=SR, normalize=False))\n",
        "\n",
        "# 実行（何度でもOK）\n",
        "show_random_norm_compare(volume=0.5)"
      ],
      "metadata": {
        "id": "MX8ZCJgkS-Xu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MFCCで前処理"
      ],
      "metadata": {
        "id": "HMZsnzwlgUsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown  MFCCで前処理を実行します\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 前処理：MFCC（X_norm → X_mfcc）\n",
        "# =========================\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "X_mfcc = []\n",
        "\n",
        "for i in range(len(X_norm)):\n",
        "    wav = X_norm[i]\n",
        "\n",
        "    # MFCC（形状: (n_mfcc, time_frames)）\n",
        "    mfcc = librosa.feature.mfcc(\n",
        "        y=wav,\n",
        "        sr=SR,\n",
        "        n_mfcc=N_MFCC,\n",
        "        hop_length=HOP_LEN,\n",
        "        n_fft=WIN_LEN\n",
        "    )\n",
        "\n",
        "    # 転置して (time_frames, n_mfcc) の形にする\n",
        "    # ESN に入れるため\n",
        "    mfcc = mfcc.T   # (T, D)\n",
        "\n",
        "    # MFCC後の発話全体を最大値でスケーリング（値域をおおよそ [-1, 1] に）\n",
        "    mfcc = mfcc / (np.max(np.abs(mfcc)) + 1e-8)\n",
        "\n",
        "    X_mfcc.append(mfcc.astype(np.float32))\n",
        "\n",
        "# Pythonリスト → オブジェクト配列（可変長 T）\n",
        "X_mfcc = np.array(X_mfcc, dtype=object)\n",
        "\n",
        "print(\"MFCC完了\")"
      ],
      "metadata": {
        "id": "lbLd-rBcgXpE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown 選択したデータからランダムに１つ選択し、MFCC後の波形を確認できます（実行のたびに変わります）\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# ランダムに1サンプル選択\n",
        "idx = np.random.randint(len(X_mfcc))\n",
        "mfcc = X_mfcc[idx]   # shape: (T, D)\n",
        "\n",
        "\n",
        "# ラベルの確認\n",
        "label_id = int(y[idx])\n",
        "label_name = CLASSES[label_id]\n",
        "print(f\"index = {idx}, label = {label_name} (id={label_id})\")\n",
        "\n",
        "\n",
        "# サンプル数の確認\n",
        "print(f\"MFCC前の波形のサンプル数：{X_norm[idx].shape[0]}\")\n",
        "T = math.floor(X_norm[idx].shape[0] / HOP_LEN) + 1\n",
        "print(f\"MFCC後の波形のサンプル数：{T}\")\n",
        "\n",
        "\n",
        "T, D = mfcc.shape\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for d in range(D):\n",
        "    plt.plot(mfcc[:, d], label=f\"MFCC {d}\")\n",
        "\n",
        "plt.title(f\"Random MFCC sample (index={idx})\")\n",
        "plt.xlabel(\"Time frame\")\n",
        "plt.ylabel(\"Normalized MFCC value\")\n",
        "plt.grid(True)\n",
        "# 次元数が多い場合は凡例を消した方が見やすい\n",
        "plt.legend(ncol=4, fontsize=8)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v8p0xkApuk1Y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Echo State Networkで学習と性能評価"
      ],
      "metadata": {
        "id": "vAqRa4nOhBPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ESNでの学習と性能評価まで一気に実施します\n",
        "\n",
        "# 学習\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "# =========================\n",
        "# 0. データ準備\n",
        "# =========================\n",
        "# X_mfcc: 各要素が (T, D) の ndarray （発話ごとのMFCC系列）\n",
        "# y:      クラスID（0〜）\n",
        "\n",
        "num_classes = len(np.unique(y))\n",
        "n_inputs = X_mfcc[0].shape[1]   # 例: 13次元, 40次元など\n",
        "\n",
        "indices = np.arange(len(X_mfcc))\n",
        "idx_train, idx_test = train_test_split(\n",
        "    indices,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "X_train = [X_mfcc[i] for i in idx_train]\n",
        "X_test  = [X_mfcc[i] for i in idx_test]\n",
        "y_train = y[idx_train]\n",
        "y_test  = y[idx_test]\n",
        "\n",
        "# ---- 情報表示 ----\n",
        "num_train_utt = len(X_train)\n",
        "num_test_utt  = len(X_test)\n",
        "total_train_frames = sum(arr.shape[0] for arr in X_train)  # 全フレーム数 (train)\n",
        "D = n_inputs\n",
        "\n",
        "print(f\"Train utterances: {num_train_utt}\")\n",
        "print(f\"Test utterances: {num_test_utt}\")\n",
        "print(\"Train class counts:\", np.bincount(y_train))\n",
        "print(\"Test  class counts:\", np.bincount(y_test))\n",
        "print(f\"Total training frames: {total_train_frames}\")\n",
        "print(f\"Feature dimension: {D}\")\n",
        "print(\"\")\n",
        "\n",
        "# =========================\n",
        "# 1. ESN（リザバー）定義（多次元入力＋density付き）\n",
        "# =========================\n",
        "\n",
        "class SimpleESN:\n",
        "    def __init__(self, n_inputs=40, n_reservoir=300,\n",
        "                 spectral_radius=0.9, density=0.05,\n",
        "                 input_scaling=0.5,\n",
        "                 leak_rate=0.3, ridge_reg=1e-6, seed=0):\n",
        "        self.n_inputs        = n_inputs\n",
        "        self.n_reservoir     = n_reservoir\n",
        "        self.spectral_radius = spectral_radius\n",
        "        self.density         = density\n",
        "        self.input_scaling   = input_scaling\n",
        "        self.leak_rate       = leak_rate\n",
        "        self.ridge_reg       = ridge_reg\n",
        "        self.seed            = seed\n",
        "        self.num_classes     = None  # 後でセット\n",
        "\n",
        "        rng = np.random.default_rng(seed)\n",
        "\n",
        "        # 入力 → リザバー（float32）\n",
        "        self.W_in = (rng.uniform(-1, 1, (n_reservoir, n_inputs))\n",
        "                    * self.input_scaling).astype(np.float32)\n",
        "\n",
        "        # バイアス（各リザバーノードに1つ）（float32）\n",
        "        self.b_in = (rng.uniform(-1, 1, n_reservoir)\n",
        "                    * self.input_scaling).astype(np.float32)\n",
        "\n",
        "\n",
        "        # リザバー内部結合（スパース化＋スペクトル半径調整）\n",
        "        W = rng.uniform(-1, 1, (n_reservoir, n_reservoir)).astype(np.float32)\n",
        "\n",
        "        if 0.0 < self.density < 1.0:\n",
        "            mask = rng.uniform(0, 1, (n_reservoir, n_reservoir)) < self.density\n",
        "            W = W * mask  # density に応じて0を入れる\n",
        "\n",
        "        # スペクトル半径を調整\n",
        "        eigvals = np.linalg.eigvals(W.astype(np.float64))\n",
        "        sr = np.max(np.abs(eigvals))\n",
        "        if sr > 0:\n",
        "            W = (W * (self.spectral_radius / sr)).astype(np.float32)\n",
        "\n",
        "        self.W = W\n",
        "        self.W_out = None\n",
        "\n",
        "    def _forward_states(self, u_seq):\n",
        "        \"\"\"\n",
        "        u_seq: (T, D) の MFCC（どんな型でもOK、ここで揃える）\n",
        "        \"\"\"\n",
        "        u_seq = np.asarray(u_seq, dtype=np.float32)\n",
        "        T, D = u_seq.shape\n",
        "        assert D == self.n_inputs\n",
        "\n",
        "        x = np.zeros(self.n_reservoir, dtype=np.float32)\n",
        "        states = np.zeros((T, self.n_reservoir), dtype=np.float32)\n",
        "\n",
        "        for t in range(T):\n",
        "            pre_activation = (\n",
        "                self.W @ x + self.W_in @ u_seq[t] + self.b_in\n",
        "            ).astype(np.float32)\n",
        "\n",
        "            x_new = np.tanh(pre_activation)\n",
        "            x = (1 - self.leak_rate) * x + self.leak_rate * x_new\n",
        "            states[t] = x\n",
        "\n",
        "        return states\n",
        "\n",
        "    def fit(self, X_seq, y_labels, num_classes):\n",
        "        \"\"\"\n",
        "        X_seq: list of (T_i, D)  発話ごとのMFCC系列\n",
        "        y_labels: (N,) 発話ラベル\n",
        "        \"\"\"\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        N = len(X_seq)\n",
        "\n",
        "        # 全フレーム数を数える（train全体）\n",
        "        total_frames = sum(np.asarray(X_seq[i]).shape[0] for i in range(N))\n",
        "\n",
        "        # H: (total_frames, 1+n_reservoir), Y: (total_frames, num_classes)\n",
        "        H = np.zeros((total_frames, 1 + self.n_reservoir), dtype=np.float32)\n",
        "        Y = np.zeros((total_frames, num_classes), dtype=np.float32)\n",
        "\n",
        "        row = 0\n",
        "        for i in range(N):\n",
        "            states = self._forward_states(X_seq[i])     # (T_i, n_reservoir)\n",
        "            T_i = states.shape[0]\n",
        "\n",
        "            # 各フレームの特徴量 [1, x(t)] を積む\n",
        "            H[row:row+T_i, 0] = 1.0\n",
        "            H[row:row+T_i, 1:] = states\n",
        "\n",
        "            # 各フレームに「その発話のラベル」を付与\n",
        "            Y[row:row+T_i, y_labels[i]] = 1.0\n",
        "\n",
        "            row += T_i\n",
        "\n",
        "        # リッジ回帰: W_out = (H^T H + λI)^(-1) H^T Y\n",
        "        Ht = H.T\n",
        "        I = np.eye(H.shape[1], dtype=np.float32)         #  (1+n_res)×(1+n_res)\n",
        "        A = Ht @ H + self.ridge_reg * I\n",
        "        B = Ht @ Y\n",
        "        self.W_out = np.linalg.solve(A.astype(np.float64), B.astype(np.float64)).astype(np.float32)\n",
        "\n",
        "    def predict_proba(self, X_seq):\n",
        "        \"\"\"\n",
        "        X_seq: list of (T_i, D)\n",
        "        戻り値: (N, num_classes)\n",
        "        → 推論：フレームごとの出力を平均して集約\n",
        "        \"\"\"\n",
        "        N = len(X_seq)\n",
        "        Y_out = np.zeros((N, self.num_classes), dtype=np.float32)\n",
        "\n",
        "        for i in range(N):\n",
        "            states = self._forward_states(X_seq[i])     # (T_i, n_res)\n",
        "            T_i = states.shape[0]\n",
        "            H = np.zeros((T_i, 1 + self.n_reservoir), dtype=np.float32)\n",
        "            H[:, 0] = 1.0\n",
        "            H[:, 1:] = states\n",
        "\n",
        "            # 各フレームの線形出力 → 平均\n",
        "            Z = H @ self.W_out                          # (T_i, num_classes)\n",
        "            Y_out[i] = Z.mean(axis=0)\n",
        "\n",
        "        return Y_out\n",
        "\n",
        "    def predict(self, X_seq):\n",
        "        \"\"\"\n",
        "        クラスID (argmax) を返す ＝ Utterance-level 予測\n",
        "        \"\"\"\n",
        "        Y_lin = self.predict_proba(X_seq)\n",
        "        return np.argmax(Y_lin, axis=1)\n",
        "\n",
        "# =========================\n",
        "# 2. ESN インスタンス作成 & 設定表示\n",
        "# =========================\n",
        "\n",
        "esn = SimpleESN(\n",
        "    n_inputs=n_inputs,\n",
        "    n_reservoir=N_RESERVOIR,\n",
        "    spectral_radius=SPECTRAL_RADIUS,\n",
        "    density=DENSITY,\n",
        "    input_scaling=INPUT_SCALING,\n",
        "    leak_rate=LEAK_RATE,\n",
        "    ridge_reg=RIDGE_REG,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "print(\"=== ESN Settings ===\")\n",
        "print(f\"n_inputs        = {esn.n_inputs}\")\n",
        "print(f\"n_reservoir     = {esn.n_reservoir}\")\n",
        "print(f\"spectral_radius = {esn.spectral_radius}\")\n",
        "print(f\"density         = {esn.density}\")\n",
        "print(f\"leak_rate       = {esn.leak_rate}\")\n",
        "print(f\"input_scaling   = {esn.input_scaling}\")\n",
        "print(f\"ridge_reg       = {esn.ridge_reg}\")\n",
        "print(f\"seed            = {esn.seed}\")\n",
        "print(f\"num_classes     = {num_classes}\")\n",
        "print(\"====================\\n\")\n",
        "\n",
        "# =========================\n",
        "# 3. ESN を学習\n",
        "# =========================\n",
        "\n",
        "esn.fit(X_train, y_train, num_classes)\n",
        "\n",
        "# =========================\n",
        "# 4. 評価（Utterance-level）\n",
        "# =========================\n",
        "\n",
        "y_train_pred = esn.predict(X_train)\n",
        "y_test_pred  = esn.predict(X_test)\n",
        "\n",
        "train_acc = accuracy_score(y_train, y_train_pred)\n",
        "test_acc  = accuracy_score(y_test,  y_test_pred)\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train accuracy: {train_acc}\")\n",
        "print(f\"Test  accuracy: {test_acc}\")\n",
        "print(\"confusion matrix:\")\n",
        "print(cm)\n",
        "print()\n",
        "print(\"Class order:\", CLASSES)"
      ],
      "metadata": {
        "id": "Q6r93rqFhCjT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 未知データでの推論"
      ],
      "metadata": {
        "id": "TcetLDzNF0yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown 未知データを音声合成で作るにあたっての設定です。\n",
        "\n",
        "# TTS生成したい言葉\n",
        "TTS_TEXT = \"stop\" # @param {type:\"string\"}\n",
        "\n",
        "# TTS生成で使う言語\n",
        "TTS_LANGUAGE = 'en' # @param [\"en\", \"ja\"]\n",
        "\n",
        "# TTS生成で使うアクセント（アメリカ、イギリス、インド）\n",
        "TTS_ACCENT = 'com' # @param [\"com\", \"co.uk\", \"co.in\"]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TIfSEuRGGNX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown 未知データを音声合成で作ります。\n",
        "\n",
        "try:\n",
        "    from gtts import gTTS\n",
        "except ImportError:\n",
        "    !pip install gTTS\n",
        "    from gtts import gTTS\n",
        "\n",
        "tts = gTTS(text=TTS_TEXT, lang=TTS_LANGUAGE, tld=TTS_ACCENT)\n",
        "tts.save(\"tts.wav\")\n",
        "print(\"saved: tts.wav\")\n",
        "display(Audio(\"tts.wav\"))\n",
        "print(TTS_TEXT)"
      ],
      "metadata": {
        "id": "hr_ooNIav0HB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown 作った音声データに対し、無音区間削除、正規化、MFCC、ESN推論まで一気に実施します\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def mfcc_from_wavfile(path):\n",
        "    # load\n",
        "    wav, _ = librosa.load(path, sr=SR)\n",
        "\n",
        "    # trim silence (same as training)\n",
        "    wav_trim = trim_silence_rms(\n",
        "        wav, sr=SR,\n",
        "        frame_length=WIN_LEN,\n",
        "        hop_length=HOP_LEN,\n",
        "        rms_thresh=0.02\n",
        "    )\n",
        "\n",
        "    # normalize (same as training)\n",
        "    wav_norm = wav_trim / (np.max(np.abs(wav_trim)) + 1e-8)\n",
        "\n",
        "    # MFCC (same params as training)\n",
        "    mfcc = librosa.feature.mfcc(\n",
        "        y=wav_norm,\n",
        "        sr=SR,\n",
        "        n_mfcc=N_MFCC,\n",
        "        hop_length=HOP_LEN,\n",
        "        n_fft=WIN_LEN,\n",
        "        center=True\n",
        "    ).T.astype(np.float32)  # (T, D)\n",
        "\n",
        "    # MFCC post-normalize (same as your MFCC code)\n",
        "    mfcc = mfcc / (np.max(np.abs(mfcc)) + 1e-8)\n",
        "\n",
        "    return mfcc\n",
        "\n",
        "# --- 推論したいファイル ---\n",
        "path = \"tts.wav\"   # 先に作ったTTS音声\n",
        "\n",
        "x_one = mfcc_from_wavfile(path)        # (T, D)\n",
        "Y_lin = esn.predict_proba([x_one])     # (1, num_classes)\n",
        "pred  = int(np.argmax(Y_lin[0]))\n",
        "\n",
        "print(\"Predicted:\", CLASSES[pred], \"( id =\", pred, \")\")\n",
        "print(\"\")\n",
        "print(\"Scores (mean linear output):\", Y_lin[0])\n",
        "print(\"Class order:\", CLASSES)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hvcmXXkPijyz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}